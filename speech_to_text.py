# -*- coding: utf-8 -*-
"""Untitled31.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rFj_ctfbMIOPKixIJzjgNyJ8jddVpFey
"""


import os
import speech_recognition as sr
from speechbrain.pretrained import SpeakerRecognition
import torch

class SpeechToText:
    def __init__(self, known_folder="recorded_voices", threshold=0.8, audio_formats=None):
        self.tokenizer = sr.Recognizer()
        self.verifier = SpeakerRecognition.from_hparams(
            source="speechbrain/spkrec-ecapa-voxceleb",
            savedir="pretrained_models/spkrec-ecapa-voxceleb"
        )
        self.known_folder = known_folder
        self.threshold = threshold
        # Allow selecting which audio formats to use; default is ['wav']
        if audio_formats is None:
            self.audio_formats = ["wav"]
        elif isinstance(audio_formats, str):
            self.audio_formats = [audio_formats.lower()]
        else:
            self.audio_formats = [fmt.lower().lstrip('.') for fmt in audio_formats]

    def transcribe(self, audio_path):
        with sr.AudioFile(audio_path) as src:
            audio = self.tokenizer.record(src)
        try:
            return self.tokenizer.recognize_google(audio)
        except sr.UnknownValueError:
            return None

    def verify_speaker(self, file1, file2):
        return self.verifier.verify_files(path_x=file1, path_y=file2)

    def is_same_speaker(self, current_path):
        total = 0
        matches = 0
        for fname in os.listdir(self.known_folder):
            ext = fname.lower().rsplit('.', 1)[-1]
            if ext not in self.audio_formats:
                continue
            total += 1
            path = os.path.join(self.known_folder, fname)
            score_tensor, detection_tensor = self.verify_speaker(current_path, path)
            if isinstance(detection_tensor, torch.Tensor):
                ratio = detection_tensor.float().mean().item()
            else:
                ratio = sum(detection_tensor) / len(detection_tensor)
            if ratio >= self.threshold:
                matches += 1
        if total == 0:
            return False, 0.0
        overall_ratio = matches / total
        return overall_ratio >= self.threshold, overall_ratio

    def process_voice(self, audio_path, flag=1):
        transcription = self.transcribe(audio_path)
        if transcription is None:
            return False, ""
        if flag == 1:
            same, _ = self.is_same_speaker(audio_path)
            return same, transcription
        return True, transcription

# if __name__ == "__main__":
#     authenticator = SpeechToText(audio_formats=["wav", "flac"])
#     same, text = authenticator.process_voice("new_voice.wav", flag=1)
#     print(same, text)

